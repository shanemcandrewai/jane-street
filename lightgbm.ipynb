{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "parallel-blood",
   "metadata": {},
   "source": [
    "# Jane Street Market Prediction\n",
    "[Kaggle Jane Street Market Prediction](https://www.kaggle.com/c/jane-street-market-prediction/overview)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fixed-gregory",
   "metadata": {},
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pointed-measurement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datatable as dt\n",
    "X = dt.fread('jane-street-market-prediction/train.csv').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "specific-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = X[X.date >= 460]\n",
    "yt = np.where((Xt.resp > 0), 1, 0)\n",
    "X = X[(X.date > 85) & (X.date < 460)]\n",
    "y = np.where((X.resp > 0), 1, 0)\n",
    "drop_cols = ['date', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp', 'ts_id']\n",
    "X.drop(drop_cols, axis=1, inplace=True)\n",
    "Xt.drop(drop_cols, axis=1, inplace=True)\n",
    "yXt = pd.concat([pd.Series(yt), Xt], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "perfect-planner",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>weight</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_120</th>\n",
       "      <th>feature_121</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390486</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.649365</td>\n",
       "      <td>-1.169996</td>\n",
       "      <td>-0.889129</td>\n",
       "      <td>-1.256179</td>\n",
       "      <td>-0.265419</td>\n",
       "      <td>-0.383478</td>\n",
       "      <td>0.526201</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.421753</td>\n",
       "      <td>-1.896874</td>\n",
       "      <td>-1.260055</td>\n",
       "      <td>1.947725</td>\n",
       "      <td>-1.994399</td>\n",
       "      <td>-1.685163</td>\n",
       "      <td>-2.866165</td>\n",
       "      <td>-0.216130</td>\n",
       "      <td>-1.892048</td>\n",
       "      <td>0.901585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390487</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.432943</td>\n",
       "      <td>5.284504</td>\n",
       "      <td>-0.337469</td>\n",
       "      <td>-0.494263</td>\n",
       "      <td>-0.442409</td>\n",
       "      <td>-0.739016</td>\n",
       "      <td>-0.064645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.677511</td>\n",
       "      <td>-0.936553</td>\n",
       "      <td>1.064936</td>\n",
       "      <td>3.119762</td>\n",
       "      <td>-0.419796</td>\n",
       "      <td>-0.208975</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>0.730166</td>\n",
       "      <td>0.648452</td>\n",
       "      <td>2.068737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390488</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.622475</td>\n",
       "      <td>-0.963682</td>\n",
       "      <td>0.532835</td>\n",
       "      <td>0.392287</td>\n",
       "      <td>0.977046</td>\n",
       "      <td>0.819693</td>\n",
       "      <td>0.140248</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.459167</td>\n",
       "      <td>-2.956745</td>\n",
       "      <td>-0.640334</td>\n",
       "      <td>-2.279663</td>\n",
       "      <td>-0.950259</td>\n",
       "      <td>-4.388417</td>\n",
       "      <td>-1.669922</td>\n",
       "      <td>-3.288939</td>\n",
       "      <td>-1.336142</td>\n",
       "      <td>-2.814239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390489</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.283405</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.463757</td>\n",
       "      <td>-1.107228</td>\n",
       "      <td>-2.286985</td>\n",
       "      <td>-3.156451</td>\n",
       "      <td>-1.690676</td>\n",
       "      <td>-2.348199</td>\n",
       "      <td>-0.683812</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.651236</td>\n",
       "      <td>-2.035894</td>\n",
       "      <td>-1.780962</td>\n",
       "      <td>0.881246</td>\n",
       "      <td>-2.202140</td>\n",
       "      <td>-1.912601</td>\n",
       "      <td>-3.341684</td>\n",
       "      <td>-0.571188</td>\n",
       "      <td>-2.185795</td>\n",
       "      <td>0.627452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390490</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.817184</td>\n",
       "      <td>-1.131577</td>\n",
       "      <td>0.541893</td>\n",
       "      <td>0.998988</td>\n",
       "      <td>0.412844</td>\n",
       "      <td>0.798855</td>\n",
       "      <td>0.198607</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.983979</td>\n",
       "      <td>-0.571013</td>\n",
       "      <td>2.483421</td>\n",
       "      <td>8.284037</td>\n",
       "      <td>-0.698486</td>\n",
       "      <td>0.199953</td>\n",
       "      <td>-0.168395</td>\n",
       "      <td>2.051091</td>\n",
       "      <td>1.726072</td>\n",
       "      <td>5.823676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426466 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0    weight  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
       "0        0.0       NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1        1.0       NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2        1.0       NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "3        0.0       NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4        1.0       NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "...      ...       ...        ...        ...        ...        ...        ...   \n",
       "2390486  NaN  0.000000        1.0  -1.649365  -1.169996  -0.889129  -1.256179   \n",
       "2390487  NaN  0.000000        1.0   2.432943   5.284504  -0.337469  -0.494263   \n",
       "2390488  NaN  0.000000        1.0  -0.622475  -0.963682   0.532835   0.392287   \n",
       "2390489  NaN  0.283405       -1.0  -1.463757  -1.107228  -2.286985  -3.156451   \n",
       "2390490  NaN  0.000000       -1.0  -1.817184  -1.131577   0.541893   0.998988   \n",
       "\n",
       "         feature_5  feature_6  feature_7  ...  feature_120  feature_121  \\\n",
       "0              NaN        NaN        NaN  ...          NaN          NaN   \n",
       "1              NaN        NaN        NaN  ...          NaN          NaN   \n",
       "2              NaN        NaN        NaN  ...          NaN          NaN   \n",
       "3              NaN        NaN        NaN  ...          NaN          NaN   \n",
       "4              NaN        NaN        NaN  ...          NaN          NaN   \n",
       "...            ...        ...        ...  ...          ...          ...   \n",
       "2390486  -0.265419  -0.383478   0.526201  ...    -2.421753    -1.896874   \n",
       "2390487  -0.442409  -0.739016  -0.064645  ...    -0.677511    -0.936553   \n",
       "2390488   0.977046   0.819693   0.140248  ...    -0.459167    -2.956745   \n",
       "2390489  -1.690676  -2.348199  -0.683812  ...    -2.651236    -2.035894   \n",
       "2390490   0.412844   0.798855   0.198607  ...    -0.983979    -0.571013   \n",
       "\n",
       "         feature_122  feature_123  feature_124  feature_125  feature_126  \\\n",
       "0                NaN          NaN          NaN          NaN          NaN   \n",
       "1                NaN          NaN          NaN          NaN          NaN   \n",
       "2                NaN          NaN          NaN          NaN          NaN   \n",
       "3                NaN          NaN          NaN          NaN          NaN   \n",
       "4                NaN          NaN          NaN          NaN          NaN   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "2390486    -1.260055     1.947725    -1.994399    -1.685163    -2.866165   \n",
       "2390487     1.064936     3.119762    -0.419796    -0.208975    -0.146749   \n",
       "2390488    -0.640334    -2.279663    -0.950259    -4.388417    -1.669922   \n",
       "2390489    -1.780962     0.881246    -2.202140    -1.912601    -3.341684   \n",
       "2390490     2.483421     8.284037    -0.698486     0.199953    -0.168395   \n",
       "\n",
       "         feature_127  feature_128  feature_129  \n",
       "0                NaN          NaN          NaN  \n",
       "1                NaN          NaN          NaN  \n",
       "2                NaN          NaN          NaN  \n",
       "3                NaN          NaN          NaN  \n",
       "4                NaN          NaN          NaN  \n",
       "...              ...          ...          ...  \n",
       "2390486    -0.216130    -1.892048     0.901585  \n",
       "2390487     0.730166     0.648452     2.068737  \n",
       "2390488    -3.288939    -1.336142    -2.814239  \n",
       "2390489    -0.571188    -2.185795     0.627452  \n",
       "2390490     2.051091     1.726072     5.823676  \n",
       "\n",
       "[426466 rows x 132 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spread-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_train = lgb.Dataset(X, y)\n",
    "lgb_eval = lgb.Dataset(Xt, yt, reference=lgb_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sophisticated-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss', 'auc'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beautiful-sydney",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.070392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[1]\tvalid_0's binary_logloss: 0.693133\tvalid_0's auc: 0.51627\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.693052\tvalid_0's auc: 0.515838\n",
      "[3]\tvalid_0's binary_logloss: 0.692973\tvalid_0's auc: 0.518485\n",
      "[4]\tvalid_0's binary_logloss: 0.692895\tvalid_0's auc: 0.51974\n",
      "[5]\tvalid_0's binary_logloss: 0.69283\tvalid_0's auc: 0.520601\n",
      "[6]\tvalid_0's binary_logloss: 0.692754\tvalid_0's auc: 0.520788\n",
      "[7]\tvalid_0's binary_logloss: 0.69274\tvalid_0's auc: 0.520858\n",
      "[8]\tvalid_0's binary_logloss: 0.692691\tvalid_0's auc: 0.520898\n",
      "[9]\tvalid_0's binary_logloss: 0.692652\tvalid_0's auc: 0.521208\n",
      "[10]\tvalid_0's binary_logloss: 0.692612\tvalid_0's auc: 0.521453\n",
      "[11]\tvalid_0's binary_logloss: 0.692577\tvalid_0's auc: 0.522066\n",
      "[12]\tvalid_0's binary_logloss: 0.692527\tvalid_0's auc: 0.522971\n",
      "[13]\tvalid_0's binary_logloss: 0.692474\tvalid_0's auc: 0.52371\n",
      "[14]\tvalid_0's binary_logloss: 0.692444\tvalid_0's auc: 0.52352\n",
      "[15]\tvalid_0's binary_logloss: 0.692397\tvalid_0's auc: 0.523889\n",
      "[16]\tvalid_0's binary_logloss: 0.692367\tvalid_0's auc: 0.524264\n",
      "[17]\tvalid_0's binary_logloss: 0.692343\tvalid_0's auc: 0.52391\n",
      "[18]\tvalid_0's binary_logloss: 0.69231\tvalid_0's auc: 0.524352\n",
      "[19]\tvalid_0's binary_logloss: 0.692276\tvalid_0's auc: 0.524502\n",
      "[20]\tvalid_0's binary_logloss: 0.692212\tvalid_0's auc: 0.525503\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's binary_logloss: 0.692212\tvalid_0's auc: 0.525503\n"
     ]
    }
   ],
   "source": [
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "understanding-remedy",
   "metadata": {},
   "source": [
    "gbm.save_model('model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "thousand-night",
   "metadata": {},
   "outputs": [
    {
     "ename": "LightGBMError",
     "evalue": "The number of features in data (132) is not the same as it was in training data (131).\nYou can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3b57504157f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dev/venv/3.8/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2956\u001b[0m                 \u001b[0mnum_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2957\u001b[0;31m         return predictor.predict(data, start_iteration, num_iteration,\n\u001b[0m\u001b[1;32m   2958\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m                                  data_has_header, is_reshape)\n",
      "\u001b[0;32m~/dev/venv/3.8/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/venv/3.8/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[0;34m(self, mat, start_iteration, num_iteration, predict_type)\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m     def __create_sparse_native(self, cs, out_shape, out_ptr_indptr, out_ptr_indices, out_ptr_data,\n",
      "\u001b[0;32m~/dev/venv/3.8/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[0;34m(mat, start_iteration, num_iteration, predict_type, preds)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length of pre-allocated predict array\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[0mout_num_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterPredictForMat(\n\u001b[0m\u001b[1;32m    648\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m                 \u001b[0mptr_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/venv/3.8/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \"\"\"\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLightGBMError\u001b[0m: The number of features in data (132) is not the same as it was in training data (131).\nYou can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing."
     ]
    }
   ],
   "source": [
    "y_pred = gbm.predict(Xt, num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print('The rmse of prediction is:', mean_squared_error(yt, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-yacht",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
