{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "standing-information",
   "metadata": {},
   "source": [
    "# Jane Street Market Prediction\n",
    "[Kaggle Jane Street Market Prediction](https://www.kaggle.com/c/jane-street-market-prediction/overview)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-subscription",
   "metadata": {},
   "source": [
    "## Calculate utility score of training set where `action` = 1 for all `resp` > 0\n",
    "[training set](https://www.kaggle.com/c/jane-street-market-prediction/data?select=train.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "confirmed-frank",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datatable as dt\n",
    "X = dt.fread('jane-street-market-prediction/train.csv').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "colored-gates",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224162.2681796676"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['pj'] = X.weight * np.where((X.resp > 0), X.resp, 0)\n",
    "pi = X.groupby(['date']).pj.sum()\n",
    "t = pi.sum()/((pi**2).sum()**0.5) * (250/pi.count())**0.5\n",
    "u = min(max(t, 0), 6) * pi.sum()\n",
    "X.drop('pj', axis=1, inplace=True)\n",
    "u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-catering",
   "metadata": {},
   "source": [
    "## Split training set and fit tree"
   ]
  },
  {
   "cell_type": "raw",
   "id": "employed-interest",
   "metadata": {},
   "source": [
    "Xt = X[X.date >= 460]\n",
    "yt = np.where((Xt.resp > 0), 1, 0)\n",
    "X = X[(X.date) > 85 & (X.date < 460)]\n",
    "y = np.where((X.resp > 0), 1, 0)\n",
    "X.drop(['date', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp', 'ts_id'], axis=1, inplace=True)\n",
    "Xt.drop(['date', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp', 'ts_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spread-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[X.date > 85]\n",
    "y = np.where((X.resp > 0), 1, 0)\n",
    "X.drop(['date', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp', 'ts_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mathematical-occasion",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 1.757 GB of training data: 7.578 s\n",
      "Binning 0.195 GB of validation data: 0.583 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.69280, val loss: 0.69285, in 0.549s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.69253, val loss: 0.69262, in 0.527s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.69228, val loss: 0.69239, in 0.509s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.69199, val loss: 0.69212, in 0.444s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.69172, val loss: 0.69188, in 0.484s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.69148, val loss: 0.69166, in 0.546s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.69127, val loss: 0.69148, in 0.421s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.69110, val loss: 0.69133, in 0.511s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.69095, val loss: 0.69120, in 0.498s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.69075, val loss: 0.69102, in 0.572s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.69057, val loss: 0.69086, in 0.651s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.69032, val loss: 0.69062, in 0.557s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.69016, val loss: 0.69046, in 0.586s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.69004, val loss: 0.69037, in 0.504s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68982, val loss: 0.69014, in 0.664s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.68964, val loss: 0.68998, in 0.444s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68950, val loss: 0.68984, in 0.540s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68936, val loss: 0.68972, in 0.562s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.68917, val loss: 0.68956, in 0.564s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.68905, val loss: 0.68947, in 0.514s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68891, val loss: 0.68933, in 0.398s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.68880, val loss: 0.68926, in 0.473s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68864, val loss: 0.68912, in 0.346s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68849, val loss: 0.68899, in 0.346s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68840, val loss: 0.68891, in 0.562s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.68830, val loss: 0.68881, in 0.529s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68819, val loss: 0.68873, in 0.464s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68811, val loss: 0.68865, in 0.481s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68803, val loss: 0.68860, in 0.585s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68790, val loss: 0.68848, in 0.334s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68777, val loss: 0.68836, in 0.332s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68765, val loss: 0.68824, in 0.378s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68751, val loss: 0.68812, in 0.479s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68735, val loss: 0.68797, in 0.533s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68727, val loss: 0.68790, in 0.532s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.68716, val loss: 0.68779, in 0.323s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68705, val loss: 0.68769, in 0.344s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68697, val loss: 0.68763, in 0.424s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68685, val loss: 0.68752, in 0.339s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68679, val loss: 0.68746, in 0.516s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68667, val loss: 0.68736, in 0.448s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68653, val loss: 0.68723, in 0.372s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68636, val loss: 0.68709, in 0.628s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.68617, val loss: 0.68689, in 0.419s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.68605, val loss: 0.68678, in 0.511s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68594, val loss: 0.68670, in 0.414s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.68584, val loss: 0.68660, in 0.326s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68568, val loss: 0.68646, in 0.530s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68556, val loss: 0.68636, in 0.533s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.68546, val loss: 0.68626, in 0.524s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68535, val loss: 0.68615, in 0.329s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68522, val loss: 0.68604, in 0.489s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68513, val loss: 0.68596, in 0.431s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68502, val loss: 0.68586, in 0.428s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68488, val loss: 0.68574, in 0.402s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.68478, val loss: 0.68566, in 0.322s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68469, val loss: 0.68557, in 0.454s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68461, val loss: 0.68550, in 0.370s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68449, val loss: 0.68540, in 0.403s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68437, val loss: 0.68528, in 0.337s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68426, val loss: 0.68518, in 0.329s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68414, val loss: 0.68505, in 0.361s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68406, val loss: 0.68499, in 0.326s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68396, val loss: 0.68491, in 0.554s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68385, val loss: 0.68481, in 0.399s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68376, val loss: 0.68474, in 0.566s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68367, val loss: 0.68466, in 0.498s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.68359, val loss: 0.68459, in 0.357s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68348, val loss: 0.68449, in 0.479s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68335, val loss: 0.68439, in 0.518s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68327, val loss: 0.68431, in 0.317s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68316, val loss: 0.68422, in 0.316s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68306, val loss: 0.68412, in 0.396s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68292, val loss: 0.68399, in 0.401s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68282, val loss: 0.68390, in 0.341s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.68275, val loss: 0.68385, in 0.443s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.68271, val loss: 0.68383, in 0.393s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68263, val loss: 0.68376, in 0.376s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68256, val loss: 0.68370, in 0.310s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68244, val loss: 0.68360, in 0.381s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 7, train loss: 0.68236, val loss: 0.68352, in 0.529s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68223, val loss: 0.68342, in 0.522s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.68213, val loss: 0.68332, in 0.329s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.68202, val loss: 0.68323, in 0.500s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68193, val loss: 0.68315, in 0.344s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68183, val loss: 0.68304, in 0.379s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68174, val loss: 0.68295, in 0.318s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68168, val loss: 0.68291, in 0.509s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68156, val loss: 0.68280, in 0.449s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68145, val loss: 0.68267, in 0.405s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.68136, val loss: 0.68259, in 0.322s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.68128, val loss: 0.68252, in 0.397s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68120, val loss: 0.68246, in 0.366s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68113, val loss: 0.68239, in 0.431s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68104, val loss: 0.68232, in 0.422s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.68092, val loss: 0.68223, in 0.496s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68083, val loss: 0.68214, in 0.328s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68074, val loss: 0.68206, in 0.455s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68067, val loss: 0.68200, in 0.422s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68055, val loss: 0.68190, in 0.501s\n",
      "Fit 100 trees in 56.305 s, (3100 total leaves)\n",
      "Time spent computing histograms: 14.026s\n",
      "Time spent finding best splits:  0.948s\n",
      "Time spent applying splits:      1.446s\n",
      "Time spent predicting:           0.425s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "clf = HistGradientBoostingClassifier(max_iter=100, verbose=1, random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sophisticated-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y"
   ]
  },
  {
   "cell_type": "raw",
   "id": "angry-translation",
   "metadata": {},
   "source": [
    "clf.score(Xt, yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sound-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('clf.pickle', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "pharmaceutical-reconstruction",
   "metadata": {},
   "source": [
    "y = np.where((X.resp > 0), 1, 0)\n",
    "X.drop(['date', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp', 'ts_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([example_sample_submission.set_index('ts_id'), example_test.set_index('ts_id')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-registration",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['pj'] = X.weight * X.action\n",
    "pi = X.groupby(['date']).pj.sum()\n",
    "t = pi.sum()/((pi**2).sum()**0.5) * (250/pi.count())**0.5\n",
    "u = min(max(t, 0), 6) * pi.sum()\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['pj'] = X.weight * np.where((X.resp > 0), X.resp, 0)\n",
    "pi = X.groupby(['date']).pj.sum()\n",
    "t = pi.sum()/((pi**2).sum()**0.5) * (250/pi.count())**0.5\n",
    "u = min(max(t, 0), 6) * pi.sum()\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "muslim-insured",
   "metadata": {},
   "source": [
    "# https://www.kaggle.com/c/jane-street-market-prediction/overview/evaluation\n",
    "import janestreet\n",
    "env = janestreet.make_env() # initialize the environment\n",
    "iter_test = env.iter_test() # an iterator which loops over the test set\n",
    "\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    sample_prediction_df.action = 0 #make your 0/1 prediction here\n",
    "    env.predict(sample_prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-documentary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
