{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "desperate-harbor",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Process input parameters\n",
      "  Using default 4 thread(s)\n",
      "  na_strings = [\"NA\"]\n",
      "  strip_whitespace = True\n",
      "  skip_blank_lines = False\n",
      "  Input is assumed to be a file name.\n",
      "File \"jane-street-market-prediction/train.csv\" opened, size: 6192438027\n",
      "[1] Prepare for reading\n",
      "  ==== file sample ====\n",
      "  date,weight,resp_1,resp_2,resp_3,resp_4,resp,feature_0,feature_1,feature_2,feature_3,feature_4,fe...\n",
      "  0,0,0.00991599128470742,0.014078579320036337,0.008773048452656298,0.0013903667296804242,0.0062703...\n",
      "  0,16.673514760471395,-0.0028282266279810245,-0.0032263220711053345,-0.007319485753127453,-0.01111...\n",
      "  0,0,0.02513386056271574,0.02760739373246317,0.03340572152082148,0.03437973777966444,0.02397012629...\n",
      "  0,0,-0.004730139135553067,-0.003272826051591346,-4.608249864155702e-4,-4.7620477938039863e-4,-0.0...\n",
      "  =====================\n",
      "LF character (\\n) found in input, \\r-only newlines will be prohibited\n",
      "[2] Detect parse settings\n",
      "  sep=',' with 100 lines of 138 fields using quote rule 0\n",
      "  Detected 138 columns\n",
      "  Quote rule = 0\n",
      "  sep = ','\n",
      "[3] Detect column types and header\n",
      "  Number of sampling jump points = 101 because the first chunk was 29152.8times smaller than the entire file\n",
      "  Type codes (jump 0): bFFFFFFiFFFFFF??FFFFFFFF??FFFFFFFF??FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF? ... FFFFFFFFFFFFFFi\n",
      "  Type codes  (final): bFFFFFFiFFFFFF??FFFFFFFF??FFFFFFFF??FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF? ... FFFFFFFFFFFFFFi\n",
      "  `header` determined to be True due to column 1 containing a string on row 1 and type Bool8/numeric in the rest of the sample\n",
      "  =====\n",
      "  Sampled 100 rows at 101 jump point(s)\n",
      "  Bytes from first data row to the end of last row: 6.19244e+09\n",
      "  Line length: mean=2132.58 sd=113.69 min=2019 max=2352\n",
      "  Estimated number of rows: 2903731\n",
      "  Initial alloc = 3194104 rows (using bytes/max(mean-2*sd,min) clamped between [1.1*estn, 2.0*estn])\n",
      "[4] Assign column names\n",
      "[5] Apply user overrides on column types\n",
      "  Allocating 138 column slots with 3194104 rows\n",
      "[6] Read the data\n",
      "  The input will be read in 5908 chunks of size 1048144 each\n",
      "[7] Finalizing the frame\n",
      "=============================\n",
      "Read 2,390,491 rows x 138 columns from 5.767GB input in 00:14.181s\n",
      " =  0.000s ( 0%) memory-mapping input file\n",
      " +  0.020s ( 0%) detecting parse parameters\n",
      " +  0.080s ( 1%) detecting column types using 100 sample rows\n",
      " +  0.002s ( 0%) allocating [3,194,104 x 138] frame (2.948GB) of which 2,390,491 ( 75%) rows used\n",
      " + 14.076s (99%) reading data\n",
      "    = 11.183s (79%) reading into row-major buffers\n",
      "    =  0.448s ( 3%) saving into the output frame\n",
      "    =  2.445s (17%) waiting\n",
      "    =  0.004s ( 0%) creating the final Frame\n",
      "=============================\n",
      "Column 15 (feature_7) bumped from Unknown to Float64 due to <<0.5760904572201109>> on row 478\n",
      "Column 16 (feature_8) bumped from Unknown to Float64 due to <<0.3035929095051141>> on row 478\n",
      "Column 80 (feature_72) bumped from Unknown to Float64 due to <<-0.14797325224330715>> on row 478\n",
      "Column 86 (feature_78) bumped from Unknown to Float64 due to <<-1.2414898559460048>> on row 478\n",
      "Column 92 (feature_84) bumped from Unknown to Float64 due to <<-0.1313198923633671>> on row 478\n",
      "Column 98 (feature_90) bumped from Unknown to Float64 due to <<2.025915273046884>> on row 478\n",
      "Column 104 (feature_96) bumped from Unknown to Float64 due to <<-0.0931756082805186>> on row 478\n",
      "Column 110 (feature_102) bumped from Unknown to Float64 due to <<2.5793728496655484>> on row 478\n",
      "Column 116 (feature_108) bumped from Unknown to Float64 due to <<-0.2452076525339114>> on row 478\n",
      "Column 122 (feature_114) bumped from Unknown to Float64 due to <<2.1876768051860624>> on row 478\n",
      "Column 25 (feature_17) bumped from Unknown to Float64 due to <<1.4521839932166298>> on row 481\n",
      "Column 26 (feature_18) bumped from Unknown to Float64 due to <<0.8279717359465736>> on row 481\n",
      "Column 35 (feature_27) bumped from Unknown to Float64 due to <<-2.861279071182605>> on row 481\n",
      "Column 36 (feature_28) bumped from Unknown to Float64 due to <<-2.4122907588373192>> on row 481\n",
      "Column 1 (date) bumped from Bool8/numeric to Int32 due to <<2>> on row 14990\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datatable as dt\n",
    "X = dt.fread('jane-street-market-prediction/train.csv', verbose=True).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "based-jersey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224162.2681796676\n"
     ]
    }
   ],
   "source": [
    "X['pj'] = X.weight * np.where((X.resp > 0), X.resp, 0)\n",
    "pi = X.groupby(['date']).pj.sum()\n",
    "t = pi.sum()/((pi**2).sum()**0.5) * (250/pi.count())**0.5\n",
    "u = min(max(t, 0), 6) * pi.sum()\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "theoretical-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.where((X.resp > 0), 1, 0)\n",
    "X.drop(['date', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp', 'ts_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "inner-shape",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 2.272 GB of training data: 12.631 s\n",
      "Binning 0.252 GB of validation data: 0.871 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.61561, val loss: 0.61563, in 0.607s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.55214, val loss: 0.55218, in 0.551s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.49923, val loss: 0.49928, in 0.558s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.45455, val loss: 0.45463, in 0.575s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.41642, val loss: 0.41649, in 0.563s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.38361, val loss: 0.38370, in 0.583s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.35517, val loss: 0.35527, in 0.605s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.33041, val loss: 0.33051, in 0.529s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.30871, val loss: 0.30882, in 1.292s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.28967, val loss: 0.28978, in 0.547s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.27291, val loss: 0.27302, in 0.554s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.25810, val loss: 0.25822, in 0.560s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.24499, val loss: 0.24510, in 0.562s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.23335, val loss: 0.23346, in 0.564s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.22301, val loss: 0.22312, in 0.582s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.21382, val loss: 0.21393, in 0.581s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.20563, val loss: 0.20574, in 0.530s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.19833, val loss: 0.19845, in 0.578s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.19181, val loss: 0.19193, in 0.591s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.18597, val loss: 0.18610, in 0.598s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.18076, val loss: 0.18090, in 0.545s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.17612, val loss: 0.17626, in 0.577s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.17197, val loss: 0.17211, in 0.569s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.16826, val loss: 0.16840, in 0.588s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.16493, val loss: 0.16508, in 0.631s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.16193, val loss: 0.16208, in 0.624s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.15926, val loss: 0.15941, in 0.704s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15688, val loss: 0.15703, in 0.860s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.15475, val loss: 0.15492, in 0.680s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.15284, val loss: 0.15302, in 0.680s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.15114, val loss: 0.15133, in 0.737s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.14961, val loss: 0.14981, in 0.729s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.14826, val loss: 0.14846, in 0.843s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.14705, val loss: 0.14726, in 0.891s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.14594, val loss: 0.14616, in 1.255s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.14497, val loss: 0.14519, in 1.316s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.14410, val loss: 0.14433, in 1.249s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.14332, val loss: 0.14356, in 0.902s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.14263, val loss: 0.14287, in 0.795s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.14200, val loss: 0.14225, in 0.806s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.14145, val loss: 0.14172, in 0.766s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.14095, val loss: 0.14124, in 0.831s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.14051, val loss: 0.14081, in 0.753s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.14011, val loss: 0.14043, in 0.779s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.13975, val loss: 0.14009, in 0.754s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.13943, val loss: 0.13980, in 0.813s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.13914, val loss: 0.13953, in 0.859s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.13888, val loss: 0.13928, in 0.846s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.13864, val loss: 0.13907, in 0.774s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.13842, val loss: 0.13888, in 1.052s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.13823, val loss: 0.13870, in 1.095s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.13804, val loss: 0.13854, in 0.763s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.13788, val loss: 0.13840, in 0.742s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.13774, val loss: 0.13827, in 0.668s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.13759, val loss: 0.13815, in 0.685s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.13747, val loss: 0.13805, in 0.561s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.13734, val loss: 0.13795, in 0.622s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.13723, val loss: 0.13788, in 0.599s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.13712, val loss: 0.13782, in 0.572s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.13702, val loss: 0.13773, in 0.635s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.13694, val loss: 0.13767, in 0.563s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.13686, val loss: 0.13761, in 0.582s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.13679, val loss: 0.13757, in 0.556s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.13672, val loss: 0.13752, in 0.553s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.13666, val loss: 0.13747, in 0.587s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.13660, val loss: 0.13744, in 0.578s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.13653, val loss: 0.13742, in 0.559s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.13646, val loss: 0.13735, in 0.548s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.13641, val loss: 0.13734, in 0.534s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.13635, val loss: 0.13729, in 0.466s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.13628, val loss: 0.13724, in 0.577s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.13623, val loss: 0.13720, in 0.422s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.13617, val loss: 0.13717, in 0.499s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.13612, val loss: 0.13714, in 0.473s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.13608, val loss: 0.13711, in 0.566s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.13603, val loss: 0.13708, in 0.604s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.13599, val loss: 0.13705, in 0.613s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.13595, val loss: 0.13702, in 0.448s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.13590, val loss: 0.13699, in 0.501s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.13586, val loss: 0.13697, in 0.547s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.13580, val loss: 0.13692, in 0.534s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.13577, val loss: 0.13691, in 0.415s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.13574, val loss: 0.13688, in 0.509s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.13571, val loss: 0.13688, in 0.447s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.13569, val loss: 0.13688, in 0.428s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.13566, val loss: 0.13685, in 0.448s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.13562, val loss: 0.13683, in 0.512s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.13560, val loss: 0.13683, in 0.436s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.13558, val loss: 0.13682, in 0.404s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.13555, val loss: 0.13680, in 0.489s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.13551, val loss: 0.13678, in 0.473s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.13548, val loss: 0.13675, in 0.539s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.13546, val loss: 0.13675, in 0.479s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.13542, val loss: 0.13673, in 0.484s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.13537, val loss: 0.13668, in 0.479s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.13534, val loss: 0.13666, in 0.496s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.13531, val loss: 0.13664, in 0.538s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.13529, val loss: 0.13664, in 0.465s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.13526, val loss: 0.13663, in 0.535s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.13521, val loss: 0.13659, in 0.536s\n",
      "Fit 100 trees in 87.871 s, (3100 total leaves)\n",
      "Time spent computing histograms: 28.449s\n",
      "Time spent finding best splits:  1.089s\n",
      "Time spent applying splits:      1.607s\n",
      "Time spent predicting:           0.716s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "gbc = HistGradientBoostingClassifier(verbose=1).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "civic-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datatable as dt\n",
    "example_sample_submission = dt.fread('jane-street-market-prediction/example_sample_submission.csv').to_pandas()\n",
    "example_test = dt.fread('jane-street-market-prediction/example_test.csv').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "russian-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([example_sample_submission.set_index('ts_id'), example_test.set_index('ts_id')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "industrial-garden",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'resp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-dbb0918972ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pj'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/venv/3.8/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5461\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5462\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'resp'"
     ]
    }
   ],
   "source": [
    "X['pj'] = X.weight * np.where((X.resp > 0), X.resp, 0)\n",
    "pi = X.groupby(['date']).pj.sum()\n",
    "t = pi.sum()/((pi**2).sum()**0.5) * (250/pi.count())**0.5\n",
    "u = min(max(t, 0), 6) * pi.sum()\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "settled-internet",
   "metadata": {},
   "source": [
    "# https://www.kaggle.com/c/jane-street-market-prediction/overview/evaluation\n",
    "import janestreet\n",
    "env = janestreet.make_env() # initialize the environment\n",
    "iter_test = env.iter_test() # an iterator which loops over the test set\n",
    "\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    sample_prediction_df.action = 0 #make your 0/1 prediction here\n",
    "    env.predict(sample_prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-popularity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
