{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "innocent-repair",
   "metadata": {},
   "source": [
    "# Jane Street Market Prediction\n",
    "[Kaggle Jane Street Market Prediction](https://www.kaggle.com/c/jane-street-market-prediction/overview)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-stress",
   "metadata": {},
   "source": [
    "## Calculate utility score of training set where `action` = 1 for all `resp` > 0\n",
    "[training set](https://www.kaggle.com/c/jane-street-market-prediction/data?select=train.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "false-cutting",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Process input parameters\n",
      "  Using default 4 thread(s)\n",
      "  na_strings = [\"NA\"]\n",
      "  strip_whitespace = True\n",
      "  skip_blank_lines = False\n",
      "  Input is assumed to be a file name.\n",
      "File \"jane-street-market-prediction/train.csv\" opened, size: 6192438027\n",
      "[1] Prepare for reading\n",
      "  ==== file sample ====\n",
      "  date,weight,resp_1,resp_2,resp_3,resp_4,resp,feature_0,feature_1,feature_2,feature_3,feature_4,fe...\n",
      "  0,0,0.00991599128470742,0.014078579320036337,0.008773048452656298,0.0013903667296804242,0.0062703...\n",
      "  0,16.673514760471395,-0.0028282266279810245,-0.0032263220711053345,-0.007319485753127453,-0.01111...\n",
      "  0,0,0.02513386056271574,0.02760739373246317,0.03340572152082148,0.03437973777966444,0.02397012629...\n",
      "  0,0,-0.004730139135553067,-0.003272826051591346,-4.608249864155702e-4,-4.7620477938039863e-4,-0.0...\n",
      "  =====================\n",
      "LF character (\\n) found in input, \\r-only newlines will be prohibited\n",
      "[2] Detect parse settings\n",
      "  sep=',' with 100 lines of 138 fields using quote rule 0\n",
      "  Detected 138 columns\n",
      "  Quote rule = 0\n",
      "  sep = ','\n",
      "[3] Detect column types and header\n",
      "  Number of sampling jump points = 101 because the first chunk was 29152.8times smaller than the entire file\n",
      "  Type codes (jump 0): bFFFFFFiFFFFFF??FFFFFFFF??FFFFFFFF??FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF? ... FFFFFFFFFFFFFFi\n",
      "  Type codes  (final): bFFFFFFiFFFFFF??FFFFFFFF??FFFFFFFF??FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF? ... FFFFFFFFFFFFFFi\n",
      "  `header` determined to be True due to column 1 containing a string on row 1 and type Bool8/numeric in the rest of the sample\n",
      "  =====\n",
      "  Sampled 100 rows at 101 jump point(s)\n",
      "  Bytes from first data row to the end of last row: 6.19244e+09\n",
      "  Line length: mean=2132.58 sd=113.69 min=2019 max=2352\n",
      "  Estimated number of rows: 2903731\n",
      "  Initial alloc = 3194104 rows (using bytes/max(mean-2*sd,min) clamped between [1.1*estn, 2.0*estn])\n",
      "[4] Assign column names\n",
      "[5] Apply user overrides on column types\n",
      "  Allocating 138 column slots with 3194104 rows\n",
      "[6] Read the data\n",
      "  The input will be read in 5908 chunks of size 1048144 each\n",
      "[7] Finalizing the frame\n",
      "=============================\n",
      "Read 2,390,491 rows x 138 columns from 5.767GB input in 00:14.720s\n",
      " =  0.000s ( 0%) memory-mapping input file\n",
      " +  0.014s ( 0%) detecting parse parameters\n",
      " +  0.082s ( 1%) detecting column types using 100 sample rows\n",
      " +  0.002s ( 0%) allocating [3,194,104 x 138] frame (2.948GB) of which 2,390,491 ( 75%) rows used\n",
      " + 14.620s (99%) reading data\n",
      "    = 11.717s (80%) reading into row-major buffers\n",
      "    =  0.437s ( 3%) saving into the output frame\n",
      "    =  2.466s (17%) waiting\n",
      "    =  0.003s ( 0%) creating the final Frame\n",
      "=============================\n",
      "Column 15 (feature_7) bumped from Unknown to Float64 due to <<0.5760904572201109>> on row 478\n",
      "Column 16 (feature_8) bumped from Unknown to Float64 due to <<0.3035929095051141>> on row 478\n",
      "Column 80 (feature_72) bumped from Unknown to Float64 due to <<-0.14797325224330715>> on row 478\n",
      "Column 86 (feature_78) bumped from Unknown to Float64 due to <<-1.2414898559460048>> on row 478\n",
      "Column 92 (feature_84) bumped from Unknown to Float64 due to <<-0.1313198923633671>> on row 478\n",
      "Column 98 (feature_90) bumped from Unknown to Float64 due to <<2.025915273046884>> on row 478\n",
      "Column 104 (feature_96) bumped from Unknown to Float64 due to <<-0.0931756082805186>> on row 478\n",
      "Column 110 (feature_102) bumped from Unknown to Float64 due to <<2.5793728496655484>> on row 478\n",
      "Column 116 (feature_108) bumped from Unknown to Float64 due to <<-0.2452076525339114>> on row 478\n",
      "Column 122 (feature_114) bumped from Unknown to Float64 due to <<2.1876768051860624>> on row 478\n",
      "Column 25 (feature_17) bumped from Unknown to Float64 due to <<1.4521839932166298>> on row 481\n",
      "Column 26 (feature_18) bumped from Unknown to Float64 due to <<0.8279717359465736>> on row 481\n",
      "Column 35 (feature_27) bumped from Unknown to Float64 due to <<-2.861279071182605>> on row 481\n",
      "Column 36 (feature_28) bumped from Unknown to Float64 due to <<-2.4122907588373192>> on row 481\n",
      "Column 1 (date) bumped from Bool8/numeric to Int32 due to <<2>> on row 14990\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datatable as dt\n",
    "X = dt.fread('jane-street-market-prediction/train.csv', verbose=True).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wireless-personality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224162.2681796676\n"
     ]
    }
   ],
   "source": [
    "X['pj'] = X.weight * np.where((X.resp > 0), X.resp, 0)\n",
    "pi = X.groupby(['date']).pj.sum()\n",
    "t = pi.sum()/((pi**2).sum()**0.5) * (250/pi.count())**0.5\n",
    "u = min(max(t, 0), 6) * pi.sum()\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-stream",
   "metadata": {},
   "source": [
    "## Calculate utility score of the mock test set where `action` = 1 for all *predicted* `resp` > 0\n",
    "[mock test set](https://www.kaggle.com/c/jane-street-market-prediction/data?select=example_test.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "racial-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.where((X.resp > 0), 1, 0)\n",
    "X.drop(['date', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp', 'ts_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prompt-palestine",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 2.272 GB of training data: 13.979 s\n",
      "Binning 0.252 GB of validation data: 1.010 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.61418, val loss: 0.61416, in 0.610s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.54952, val loss: 0.54949, in 0.555s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.49563, val loss: 0.49559, in 0.569s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.45003, val loss: 0.44999, in 0.568s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.41110, val loss: 0.41105, in 0.540s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.37754, val loss: 0.37749, in 0.512s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.34845, val loss: 0.34841, in 0.505s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.32304, val loss: 0.32301, in 0.522s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.30077, val loss: 0.30074, in 0.525s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.28119, val loss: 0.28116, in 0.528s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.26389, val loss: 0.26387, in 0.524s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.24858, val loss: 0.24856, in 0.515s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.23497, val loss: 0.23496, in 0.535s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.22285, val loss: 0.22286, in 0.530s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.21204, val loss: 0.21206, in 0.529s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.20242, val loss: 0.20245, in 0.491s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.19381, val loss: 0.19384, in 0.513s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.18609, val loss: 0.18613, in 0.495s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.17916, val loss: 0.17920, in 0.544s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.17293, val loss: 0.17299, in 0.527s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.16735, val loss: 0.16742, in 0.669s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.16234, val loss: 0.16241, in 0.530s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.15783, val loss: 0.15792, in 0.545s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.15376, val loss: 0.15384, in 0.506s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.15009, val loss: 0.15019, in 0.596s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.14677, val loss: 0.14687, in 0.531s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.14379, val loss: 0.14391, in 0.461s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.14111, val loss: 0.14124, in 0.508s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.13868, val loss: 0.13883, in 0.549s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.13649, val loss: 0.13664, in 0.452s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.13447, val loss: 0.13463, in 0.530s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.13266, val loss: 0.13283, in 0.512s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.13104, val loss: 0.13122, in 0.508s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12957, val loss: 0.12975, in 0.447s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.12823, val loss: 0.12842, in 0.484s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.12702, val loss: 0.12721, in 0.495s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12592, val loss: 0.12614, in 0.454s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12494, val loss: 0.12516, in 0.442s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12405, val loss: 0.12429, in 0.475s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.12324, val loss: 0.12349, in 0.507s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.12250, val loss: 0.12277, in 0.490s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.12183, val loss: 0.12211, in 0.541s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.12124, val loss: 0.12153, in 0.459s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.12068, val loss: 0.12097, in 0.464s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.12016, val loss: 0.12046, in 0.517s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.11969, val loss: 0.12000, in 0.526s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.11927, val loss: 0.11959, in 0.457s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.11889, val loss: 0.11923, in 0.483s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11854, val loss: 0.11889, in 0.492s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 17, train loss: 0.11823, val loss: 0.11859, in 0.460s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.11794, val loss: 0.11833, in 0.547s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.11768, val loss: 0.11807, in 0.492s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.11744, val loss: 0.11784, in 0.457s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.11723, val loss: 0.11764, in 0.482s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.11703, val loss: 0.11746, in 0.502s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.11681, val loss: 0.11725, in 0.516s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11663, val loss: 0.11708, in 0.516s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11648, val loss: 0.11694, in 0.529s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11633, val loss: 0.11680, in 0.449s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11620, val loss: 0.11668, in 0.450s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.11608, val loss: 0.11657, in 0.497s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.11598, val loss: 0.11648, in 0.479s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.11587, val loss: 0.11638, in 0.582s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 19, train loss: 0.11577, val loss: 0.11630, in 0.474s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.11567, val loss: 0.11621, in 0.488s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11556, val loss: 0.11610, in 0.553s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11545, val loss: 0.11600, in 0.535s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.11538, val loss: 0.11594, in 0.504s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11531, val loss: 0.11589, in 0.462s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.11524, val loss: 0.11583, in 0.536s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11518, val loss: 0.11578, in 0.592s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.11512, val loss: 0.11573, in 0.520s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11508, val loss: 0.11569, in 0.474s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.11501, val loss: 0.11564, in 0.517s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.11496, val loss: 0.11560, in 0.463s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.11489, val loss: 0.11552, in 0.506s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.11485, val loss: 0.11550, in 0.463s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11481, val loss: 0.11547, in 0.440s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.11478, val loss: 0.11545, in 0.475s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11474, val loss: 0.11541, in 0.460s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.11470, val loss: 0.11540, in 0.502s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.11467, val loss: 0.11537, in 0.444s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11464, val loss: 0.11536, in 0.448s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.11460, val loss: 0.11533, in 0.504s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.11458, val loss: 0.11531, in 0.432s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.11454, val loss: 0.11528, in 0.469s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.11451, val loss: 0.11528, in 0.448s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.11448, val loss: 0.11525, in 0.449s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.11445, val loss: 0.11523, in 0.435s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.11442, val loss: 0.11520, in 0.472s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.11439, val loss: 0.11518, in 0.451s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.11437, val loss: 0.11518, in 0.442s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.11433, val loss: 0.11515, in 0.501s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.11429, val loss: 0.11512, in 0.482s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.11424, val loss: 0.11508, in 0.462s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.11422, val loss: 0.11507, in 0.524s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.11418, val loss: 0.11504, in 0.509s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.11415, val loss: 0.11502, in 0.565s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.11413, val loss: 0.11501, in 0.553s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.11410, val loss: 0.11499, in 0.538s\n",
      "Fit 100 trees in 71.994 s, (3100 total leaves)\n",
      "Time spent computing histograms: 18.263s\n",
      "Time spent finding best splits:  0.754s\n",
      "Time spent applying splits:      1.057s\n",
      "Time spent predicting:           0.440s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "gbc = HistGradientBoostingClassifier(verbose=1).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prime-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "retired-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datatable as dt\n",
    "example_sample_submission = dt.fread('jane-street-market-prediction/example_sample_submission.csv').to_pandas()\n",
    "example_test = dt.fread('jane-street-market-prediction/example_test.csv').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "tutorial-kingston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_id</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15214</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15215</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15216</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15217</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15218</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15219 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ts_id  action\n",
       "0        0.0     NaN\n",
       "1        NaN     NaN\n",
       "2        NaN     NaN\n",
       "3        NaN     NaN\n",
       "4        NaN     NaN\n",
       "...      ...     ...\n",
       "15214    NaN     NaN\n",
       "15215    NaN     NaN\n",
       "15216    NaN     NaN\n",
       "15217    NaN     NaN\n",
       "15218    NaN     NaN\n",
       "\n",
       "[15219 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = gbc.predict(example_test.drop('date', 1))\n",
    "pred[pred == 0]\n",
    "example_sample_submission[example_sample_submission == 0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "awful-letter",
   "metadata": {},
   "source": [
    "y = np.where((X.resp > 0), 1, 0)\n",
    "X.drop(['date', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp', 'ts_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([example_sample_submission.set_index('ts_id'), example_test.set_index('ts_id')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['pj'] = X.weight * X.action\n",
    "pi = X.groupby(['date']).pj.sum()\n",
    "t = pi.sum()/((pi**2).sum()**0.5) * (250/pi.count())**0.5\n",
    "u = min(max(t, 0), 6) * pi.sum()\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['pj'] = X.weight * np.where((X.resp > 0), X.resp, 0)\n",
    "pi = X.groupby(['date']).pj.sum()\n",
    "t = pi.sum()/((pi**2).sum()**0.5) * (250/pi.count())**0.5\n",
    "u = min(max(t, 0), 6) * pi.sum()\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "vietnamese-intranet",
   "metadata": {},
   "source": [
    "# https://www.kaggle.com/c/jane-street-market-prediction/overview/evaluation\n",
    "import janestreet\n",
    "env = janestreet.make_env() # initialize the environment\n",
    "iter_test = env.iter_test() # an iterator which loops over the test set\n",
    "\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    sample_prediction_df.action = 0 #make your 0/1 prediction here\n",
    "    env.predict(sample_prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-drill",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
