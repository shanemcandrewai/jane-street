{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "coordinate-experience",
   "metadata": {},
   "source": [
    "# Jane Street Market Prediction\n",
    "[Kaggle Jane Street Market Prediction](https://www.kaggle.com/c/jane-street-market-prediction/overview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acceptable-flexibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datatable as dt\n",
    "X = dt.fread('jane-street-market-prediction/train.csv').to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-checkout",
   "metadata": {},
   "source": [
    "## Calculate utility score of training set where `action` = 1 for all `resp` > 0\n",
    "[training set](https://www.kaggle.com/c/jane-street-market-prediction/data?select=train.csv)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "resistant-parking",
   "metadata": {},
   "source": [
    "X['pj'] = X.weight * np.where((X.resp > 0), X.resp, 0)\n",
    "pi = X.groupby(['date']).pj.sum()\n",
    "t = pi.sum()/((pi**2).sum()**0.5) * (250/pi.count())**0.5\n",
    "u = min(max(t, 0), 6) * pi.sum()\n",
    "X.drop('pj', axis=1, inplace=True)\n",
    "del pi\n",
    "u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-plate",
   "metadata": {},
   "source": [
    "### Utility score\n",
    "224162.2681796676"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-france",
   "metadata": {},
   "source": [
    "## Split training set and fit tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "democratic-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = X[X.date >= 460]\n",
    "yt = np.where((Xt.resp > 0), 1, 0)\n",
    "X = X[(X.date) > 85 & (X.date < 460)]\n",
    "y = np.where((X.resp > 0), 1, 0)\n",
    "X.drop(['date', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp', 'ts_id'], axis=1, inplace=True)\n",
    "Xt.drop(['date', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp', 'ts_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "historical-belgium",
   "metadata": {},
   "source": [
    "X = X[X.date > 85]\n",
    "y = np.where((X.resp > 0), 1, 0)\n",
    "X.drop(['date', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp', 'ts_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unsigned-county",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 2.241 GB of training data: 24.128 s\n",
      "Binning 0.249 GB of validation data: 1.756 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.69274, val loss: 0.69275, in 2.281s\n",
      "[2/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.69241, val loss: 0.69244, in 2.008s\n",
      "[3/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.69211, val loss: 0.69214, in 2.067s\n",
      "[4/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.69182, val loss: 0.69186, in 2.208s\n",
      "[5/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.69150, val loss: 0.69157, in 2.310s\n",
      "[6/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.69127, val loss: 0.69136, in 2.111s\n",
      "[7/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.69107, val loss: 0.69117, in 2.110s\n",
      "[8/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.69082, val loss: 0.69092, in 2.867s\n",
      "[9/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.69064, val loss: 0.69076, in 2.195s\n",
      "[10/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.69042, val loss: 0.69056, in 1.966s\n",
      "[11/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.69025, val loss: 0.69039, in 2.434s\n",
      "[12/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.69009, val loss: 0.69025, in 2.417s\n",
      "[13/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68994, val loss: 0.69012, in 2.478s\n",
      "[14/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.68981, val loss: 0.69000, in 2.753s\n",
      "[15/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68964, val loss: 0.68985, in 2.102s\n",
      "[16/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68950, val loss: 0.68972, in 2.020s\n",
      "[17/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.68936, val loss: 0.68960, in 2.099s\n",
      "[18/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68920, val loss: 0.68946, in 1.804s\n",
      "[19/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.68907, val loss: 0.68934, in 2.238s\n",
      "[20/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68889, val loss: 0.68919, in 2.099s\n",
      "[21/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.68875, val loss: 0.68905, in 2.281s\n",
      "[22/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68860, val loss: 0.68892, in 2.201s\n",
      "[23/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68844, val loss: 0.68877, in 2.466s\n",
      "[24/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.68834, val loss: 0.68869, in 1.915s\n",
      "[25/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68819, val loss: 0.68856, in 2.038s\n",
      "[26/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.68806, val loss: 0.68843, in 1.425s\n",
      "[27/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68794, val loss: 0.68832, in 1.698s\n",
      "[28/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68786, val loss: 0.68824, in 2.249s\n",
      "[29/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68774, val loss: 0.68814, in 1.951s\n",
      "[30/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68758, val loss: 0.68798, in 1.539s\n",
      "[31/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68742, val loss: 0.68784, in 1.883s\n",
      "[32/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68731, val loss: 0.68774, in 1.719s\n",
      "[33/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.68721, val loss: 0.68765, in 2.111s\n",
      "[34/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68712, val loss: 0.68758, in 1.990s\n",
      "[35/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68701, val loss: 0.68749, in 2.517s\n",
      "[36/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68688, val loss: 0.68737, in 1.768s\n",
      "[37/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68675, val loss: 0.68725, in 1.438s\n",
      "[38/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68661, val loss: 0.68712, in 1.906s\n",
      "[39/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.68648, val loss: 0.68700, in 2.306s\n",
      "[40/100] 1 tree, 31 leaves, max depth = 16, train loss: 0.68638, val loss: 0.68692, in 2.080s\n",
      "[41/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68630, val loss: 0.68685, in 1.888s\n",
      "[42/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68623, val loss: 0.68681, in 2.230s\n",
      "[43/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68612, val loss: 0.68671, in 1.677s\n",
      "[44/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68602, val loss: 0.68662, in 1.288s\n",
      "[45/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68593, val loss: 0.68653, in 1.477s\n",
      "[46/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68583, val loss: 0.68645, in 2.312s\n",
      "[47/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68577, val loss: 0.68640, in 2.322s\n",
      "[48/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68565, val loss: 0.68630, in 1.780s\n",
      "[49/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68556, val loss: 0.68621, in 1.277s\n",
      "[50/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68547, val loss: 0.68614, in 1.771s\n",
      "[51/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.68539, val loss: 0.68608, in 2.509s\n",
      "[52/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68531, val loss: 0.68600, in 1.834s\n",
      "[53/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68524, val loss: 0.68595, in 1.773s\n",
      "[54/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68514, val loss: 0.68586, in 1.512s\n",
      "[55/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68501, val loss: 0.68573, in 1.522s\n",
      "[56/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68491, val loss: 0.68564, in 2.745s\n",
      "[57/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68480, val loss: 0.68554, in 1.360s\n",
      "[58/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68473, val loss: 0.68548, in 2.120s\n",
      "[59/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68464, val loss: 0.68541, in 1.858s\n",
      "[60/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.68457, val loss: 0.68535, in 1.355s\n",
      "[61/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68447, val loss: 0.68527, in 1.395s\n",
      "[62/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68436, val loss: 0.68516, in 1.524s\n",
      "[63/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68426, val loss: 0.68508, in 1.515s\n",
      "[64/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.68413, val loss: 0.68497, in 1.725s\n",
      "[65/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68401, val loss: 0.68486, in 2.373s\n",
      "[66/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68395, val loss: 0.68481, in 2.207s\n",
      "[67/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68385, val loss: 0.68472, in 1.651s\n",
      "[68/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68378, val loss: 0.68466, in 1.416s\n",
      "[69/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68371, val loss: 0.68460, in 1.312s\n",
      "[70/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68363, val loss: 0.68453, in 1.679s\n",
      "[71/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.68358, val loss: 0.68449, in 2.545s\n",
      "[72/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68353, val loss: 0.68445, in 1.518s\n",
      "[73/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68343, val loss: 0.68435, in 2.162s\n",
      "[74/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.68334, val loss: 0.68427, in 1.344s\n",
      "[75/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68326, val loss: 0.68420, in 3.658s\n",
      "[76/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.68319, val loss: 0.68415, in 1.805s\n",
      "[77/100] 1 tree, 31 leaves, max depth = 14, train loss: 0.68309, val loss: 0.68405, in 2.603s\n",
      "[78/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.68302, val loss: 0.68400, in 2.046s\n",
      "[79/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68297, val loss: 0.68397, in 1.730s\n",
      "[80/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68287, val loss: 0.68389, in 1.848s\n",
      "[81/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68281, val loss: 0.68384, in 2.067s\n",
      "[82/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68269, val loss: 0.68373, in 1.430s\n",
      "[83/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68263, val loss: 0.68369, in 1.315s\n",
      "[84/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68253, val loss: 0.68359, in 1.391s\n",
      "[85/100] 1 tree, 31 leaves, max depth = 11, train loss: 0.68245, val loss: 0.68351, in 1.473s\n",
      "[86/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68235, val loss: 0.68341, in 1.481s\n",
      "[87/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68230, val loss: 0.68338, in 2.434s\n",
      "[88/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.68223, val loss: 0.68333, in 1.405s\n",
      "[89/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68218, val loss: 0.68330, in 1.342s\n",
      "[90/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68207, val loss: 0.68320, in 1.688s\n",
      "[91/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68200, val loss: 0.68314, in 1.313s\n",
      "[92/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68191, val loss: 0.68306, in 1.474s\n",
      "[93/100] 1 tree, 31 leaves, max depth = 8, train loss: 0.68185, val loss: 0.68299, in 1.604s\n",
      "[94/100] 1 tree, 31 leaves, max depth = 12, train loss: 0.68174, val loss: 0.68289, in 1.541s\n",
      "[95/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68169, val loss: 0.68284, in 1.293s\n",
      "[96/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68161, val loss: 0.68277, in 1.836s\n",
      "[97/100] 1 tree, 31 leaves, max depth = 15, train loss: 0.68155, val loss: 0.68272, in 1.640s\n",
      "[98/100] 1 tree, 31 leaves, max depth = 10, train loss: 0.68147, val loss: 0.68264, in 1.528s\n",
      "[99/100] 1 tree, 31 leaves, max depth = 9, train loss: 0.68142, val loss: 0.68261, in 1.956s\n",
      "[100/100] 1 tree, 31 leaves, max depth = 13, train loss: 0.68133, val loss: 0.68252, in 1.351s\n",
      "Fit 100 trees in 254.777 s, (3100 total leaves)\n",
      "Time spent computing histograms: 64.169s\n",
      "Time spent finding best splits:  4.048s\n",
      "Time spent applying splits:      5.286s\n",
      "Time spent predicting:           1.085s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "clf = HistGradientBoostingClassifier(max_iter=100, verbose=1, random_state=1000).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "touched-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "brazilian-cheat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.545623801193999"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(Xt, yt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-maldives",
   "metadata": {},
   "source": [
    "### max_iter=100, verbose=1, random_state=None\n",
    "0.5455018688476925"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-bacon",
   "metadata": {},
   "source": [
    "### max_iter=100, verbose=1, random_state=1\n",
    "0.545544076198337"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-surgery",
   "metadata": {},
   "source": [
    "### max_iter=100, verbose=1, random_state=100\n",
    "0.5440808880426575"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-midwest",
   "metadata": {},
   "source": [
    "### max_iter=100, verbose=1, random_state=1000\n",
    "0.545623801193999"
   ]
  },
  {
   "cell_type": "raw",
   "id": "compact-yeast",
   "metadata": {},
   "source": [
    "import pickle\n",
    "with open('clf.pickle', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "collect-pastor",
   "metadata": {},
   "source": [
    "y = np.where((X.resp > 0), 1, 0)\n",
    "X.drop(['date', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp', 'ts_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([example_sample_submission.set_index('ts_id'), example_test.set_index('ts_id')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['pj'] = X.weight * X.action\n",
    "pi = X.groupby(['date']).pj.sum()\n",
    "t = pi.sum()/((pi**2).sum()**0.5) * (250/pi.count())**0.5\n",
    "u = min(max(t, 0), 6) * pi.sum()\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['pj'] = X.weight * np.where((X.resp > 0), X.resp, 0)\n",
    "pi = X.groupby(['date']).pj.sum()\n",
    "t = pi.sum()/((pi**2).sum()**0.5) * (250/pi.count())**0.5\n",
    "u = min(max(t, 0), 6) * pi.sum()\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "registered-audio",
   "metadata": {},
   "source": [
    "# https://www.kaggle.com/c/jane-street-market-prediction/overview/evaluation\n",
    "import janestreet\n",
    "env = janestreet.make_env() # initialize the environment\n",
    "iter_test = env.iter_test() # an iterator which loops over the test set\n",
    "\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    sample_prediction_df.action = 0 #make your 0/1 prediction here\n",
    "    env.predict(sample_prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-nudist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
